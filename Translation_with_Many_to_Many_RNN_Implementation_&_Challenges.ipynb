{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "443eccda",
      "metadata": {
        "id": "443eccda"
      },
      "source": [
        "# Part 1: Many-to-Many Recurrent Neural Network (RNN) Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lvVpPM2sJtw",
        "outputId": "64c739f6-bb8f-4706-bc22-39f0108c1b68"
      },
      "id": "2lvVpPM2sJtw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsVsKyXOxnrh",
        "outputId": "ff99a3b8-0b91-4af2-9da3-d540fef898e6"
      },
      "id": "qsVsKyXOxnrh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji # Changed package name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHojEgKexEs5",
        "outputId": "f13434f6-9c96-4264-f614-2d846b67ad28"
      },
      "id": "MHojEgKexEs5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/586.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m471.0/586.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPpbDzdbxmb1"
      },
      "id": "BPpbDzdbxmb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd63a7a",
      "metadata": {
        "id": "ecd63a7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import LughaatNLP\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, BatchNormalization, TimeDistributed, Dropout, Embedding\n",
        "import numpy as np\n",
        "import emoji\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbbe1ee",
      "metadata": {
        "id": "7fbbe1ee"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcdecb88",
      "metadata": {
        "id": "fcdecb88"
      },
      "outputs": [],
      "source": [
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "def remove_emoji_and_noise(text):\n",
        "    text = emoji.replace_emoji(text, replace='')  # Remove emojis\n",
        "    return text\n",
        "\n",
        "# Example normalize function (you may replace it with a Lughaat-based normalization library)\n",
        "def normalize_english(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "def normalize_urdu(text):\n",
        "    text = text.replace('آ', 'ا')  # Example normalization: Replace \"آ\" with \"ا\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "def count_unique_words(sentences):\n",
        "    unique_words = set()\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()  # Split sentence into words\n",
        "        unique_words.update(words)  # Add words to the set\n",
        "    return len(unique_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1f3bcd",
      "metadata": {
        "id": "2b1f3bcd"
      },
      "source": [
        "## Data Preparation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88d9862f",
      "metadata": {
        "id": "88d9862f"
      },
      "source": [
        "### reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "048abeaa",
      "metadata": {
        "id": "048abeaa"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_excel('parallel-corpus.xlsx')\n",
        "\n",
        "# Extract first two columns\n",
        "first_two_columns = data.iloc[:, :2]\n",
        "\n",
        "# Assuming the first column is English and the second column is Urdu\n",
        "english_sentences = first_two_columns.iloc[:, 0].astype(str).values  # First column for English\n",
        "urdu_sentences = first_two_columns.iloc[:, 1].astype(str).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a31660",
      "metadata": {
        "id": "c6a31660"
      },
      "source": [
        "### Normalizing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79d20d1",
      "metadata": {
        "id": "d79d20d1"
      },
      "outputs": [],
      "source": [
        "# Assuming 'english_sentences' and 'urdu_sentences' are your original lists of sentences\n",
        "english_sentences_cleaned = [remove_emoji_and_noise(lemmatize_text(sentence)) for sentence in english_sentences]\n",
        "urdu_sentences_cleaned = [remove_emoji_and_noise(lemmatize_text(sentence)) for sentence in urdu_sentences]\n",
        "\n",
        "# Normalize sentences\n",
        "english_sentences_normalized = [normalize_english(sentence) for sentence in english_sentences_cleaned]\n",
        "urdu_sentences_normalized = [normalize_urdu(sentence) for sentence in urdu_sentences_cleaned]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389018f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "389018f9",
        "outputId": "6bb066f3-f6bc-4506-c900-714150612b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How can I communicate with my parents?' 'How can I make friends?’'\n",
            " 'Why do I get so sad?’'\n",
            " 'If you’ve asked yourself such questions, you’re not alone.'\n",
            " 'Depending on where you’ve turned for guidance, you may have been given conflicting answers.'\n",
            " 'To help young people get solid advice they can rely on, Awake! magazine launched the Bible-based series entitled “Young People Ask .'\n",
            " 'in January1982. Decades later, the series still draws an enthusiastic response.'\n",
            " 'Each article is the product of extensive research. In fact, to determine just how young people think and feel, Awake!'\n",
            " 'The book you now hold was originally published in 1989.'\n",
            " 'However, the chapters have been completely revised to address the issues of today.']\n",
            "['میں اپنے والدین سے کیسے بات کروں ؟' 'میں دوست کیسے بنائوں ؟'\n",
            " 'میں اتنا اداس کیوں ہوں؟.'\n",
            " 'اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آپ اکیلے نہیں ہیں'\n",
            " ' اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں گئے ہیں، ہو سکتا ہے آپ کو متضاد جوابات دیے گئے ہوں۔'\n",
            " 'نوجوانوں کو ٹھوس مشورے حاصل کرنے میں مدد کرنے کے لیے جس پر وہ بھروسہ کر سکتے ہیں، جاگو! میگزین نے بائبل پر مبنی رسالہ شروع کیا۔'\n",
            " '8 جنوری 1982۔ دہائیوں کے بعد، سیریز اب بھی ایک پرجوش ردعمل کھینچتی ہے۔'\n",
            " 'درحقیقت، اس بات کا تعین کرنے کے لیے کہ نوجوان کیسے سوچتے اور محسوس کرتے ہیں، جاگو!'\n",
            " 'جو کتاب آپ کے پاس ہے وہ اصل میں 1989 میں شائع ہوئی تھی۔'\n",
            " '                                                                                                              (آج کے مسائل کو حل کرنے کے لیے ابواب پر مکمل نظر ثانی کی گئی ہے۔)                         ']\n"
          ]
        }
      ],
      "source": [
        "print(english_sentences[:10])\n",
        "print(urdu_sentences[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ded4f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ded4f6b",
        "outputId": "a593b21f-9b67-4acc-8680-6f26e8a17f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how can i communicate with my parent ', 'how can i make friend  ', 'why do i get so sad  ', 'if you  ve asked yourself such question  you  re not alone ', 'depending on where you  ve turned for guidance  you may have been given conflicting answer ', 'to help young people get solid advice they can rely on  awake  magazine launched the biblebased series entitled  young people ask ', 'in january1982  decades later  the series still draw an enthusiastic response ', 'each article is the product of extensive research  in fact  to determine just how young people think and feel  awake ', 'the book you now hold wa originally published in 1989 ', 'however  the chapter have been completely revised to address the issue of today ']\n",
            "['میں اپنے والدین سے کیسے بات کروں ', 'میں دوست کیسے بنائوں ', 'میں اتنا اداس کیوں ہوں ', 'اگر اپ نے اپنے اپ سے ایسے سوالات کیے ہیں تو اپ اکیلے نہیں ہیں', 'اس بات پر منحصر ہے کہ اپ رہنمائی کے لیے کہاں گئے ہیں ہو سکتا ہے اپ کو متضاد جوابات دیے گئے ہوں', 'نوجوانوں کو ٹھوس مشورے حاصل کرنے میں مدد کرنے کے لیے جس پر وہ بھروسہ کر سکتے ہیں جاگو  میگزین نے بائبل پر مبنی رسالہ شروع کیا', '8 جنوری 1982 دہائیوں کے بعد سیریز اب بھی ایک پرجوش ردعمل کھینچتی ہے', 'درحقیقت اس بات کا تعین کرنے کے لیے کہ نوجوان کیسے سوچتے اور محسوس کرتے ہیں جاگو ', 'جو کتاب اپ کے پاس ہے وہ اصل میں 1989 میں شائع ہوئی تھی', ' اج کے مسائل کو حل کرنے کے لیے ابواب پر مکمل نظر ثانی کی گئی ہے ']\n"
          ]
        }
      ],
      "source": [
        "print(english_sentences_normalized[:10])\n",
        "print(urdu_sentences_normalized[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a16bcb0c",
      "metadata": {
        "id": "a16bcb0c"
      },
      "source": [
        "### Spliting data into train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d65be9",
      "metadata": {
        "id": "c7d65be9"
      },
      "outputs": [],
      "source": [
        "# Shuffle and split the data into training (80%), validation (10%), and test (10%)\n",
        "train_size = int(0.8 * len(data))\n",
        "val_size = int(0.1 * len(data))\n",
        "\n",
        "# Shuffle data before splitting\n",
        "#data = data.sample(frac=1, random_state=42)\n",
        "\n",
        "# Split data\n",
        "train_data = data.iloc[:train_size]\n",
        "val_data = data.iloc[train_size:train_size+val_size]\n",
        "test_data = data.iloc[train_size+val_size:]\n",
        "\n",
        "# Separate English and Urdu sentences for each split\n",
        "english_train = train_data.iloc[:, 0].astype(str).values\n",
        "urdu_train = train_data.iloc[:, 1].astype(str).values\n",
        "\n",
        "english_val = val_data.iloc[:, 0].astype(str).values\n",
        "urdu_val = val_data.iloc[:, 1].astype(str).values\n",
        "\n",
        "english_test = test_data.iloc[:, 0].astype(str).values\n",
        "urdu_test = test_data.iloc[:, 1].astype(str).values\n",
        "\n",
        "# Normalize the split data\n",
        "english_train_normalized = [normalize_english(sentence) for sentence in english_train]\n",
        "urdu_train_normalized = [normalize_urdu(sentence) for sentence in urdu_train]\n",
        "english_val_normalized = [normalize_english(sentence) for sentence in english_val]\n",
        "urdu_val_normalized = [normalize_urdu(sentence) for sentence in urdu_val]\n",
        "english_test_normalized = [normalize_english(sentence) for sentence in english_test]\n",
        "urdu_test_normalized = [normalize_urdu(sentence) for sentence in urdu_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d031ca",
      "metadata": {
        "id": "48d031ca"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937231af",
      "metadata": {
        "id": "937231af"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=16000,oov_token='OOV')\n",
        "\n",
        "# Tokenize English sentences\n",
        "tokenizer.fit_on_texts(english_train_normalized)  # Fit on normalized training data\n",
        "english_train_sequences = tokenizer.texts_to_sequences(english_train_normalized)\n",
        "english_val_sequences = tokenizer.texts_to_sequences(english_val_normalized)\n",
        "english_test_sequences = tokenizer.texts_to_sequences(english_test_normalized)\n",
        "\n",
        "# Tokenize Urdu sentences\n",
        "tokenizer.fit_on_texts(urdu_train_normalized)  # Fit on normalized training data\n",
        "urdu_train_sequences = tokenizer.texts_to_sequences(urdu_train_normalized)\n",
        "urdu_val_sequences = tokenizer.texts_to_sequences(urdu_val_normalized)\n",
        "urdu_test_sequences = tokenizer.texts_to_sequences(urdu_test_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7627a260",
      "metadata": {
        "id": "7627a260"
      },
      "source": [
        "### Padding of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785249c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "785249c8",
        "outputId": "133fddfb-d7c8-4f9c-d4a7-99f4697a4e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English vocabulary size: 29270\n",
            "Urdu vocabulary size: 29270\n"
          ]
        }
      ],
      "source": [
        "# Define a fixed maximum sequence length\n",
        "max_length = 5\n",
        "\n",
        "# Pad sequences to a uniform length of 10\n",
        "english_train_sequences = pad_sequences(english_train_sequences, maxlen=max_length, padding='post')\n",
        "english_val_sequences = pad_sequences(english_val_sequences, maxlen=max_length, padding='post')\n",
        "english_test_sequences = pad_sequences(english_test_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "urdu_train_sequences = pad_sequences(urdu_train_sequences, maxlen=max_length, padding='post')\n",
        "urdu_val_sequences = pad_sequences(urdu_val_sequences, maxlen=max_length, padding='post')\n",
        "urdu_test_sequences = pad_sequences(urdu_test_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Count vocabulary size\n",
        "english_vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
        "urdu_vocab_size = len(tokenizer.word_index) + 1        # +1 for padding token\n",
        "\n",
        "# Print vocabulary sizes\n",
        "print(\"\\nEnglish vocabulary size:\", english_vocab_size)\n",
        "print(\"Urdu vocabulary size:\", urdu_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f6dd08",
      "metadata": {
        "id": "f1f6dd08"
      },
      "source": [
        "### Preparing sequences to maintain context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f79bb87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f79bb87",
        "outputId": "eab708da-0a33-408d-af8e-bcfc594cebb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24131, 5) (24131, 5)\n",
            "(3016, 5) (3016, 5)\n",
            "(3017, 5) (3017, 5)\n"
          ]
        }
      ],
      "source": [
        "# Prepare sequences for training and validation: X is input, y is the shifted output (next token)\n",
        "def prepare_sequences(input_sequences, output_sequences, max_length):\n",
        "    X = input_sequences\n",
        "    y = []\n",
        "\n",
        "    # Shift the output sequence by 1 (to predict the next token)\n",
        "    for i in range(len(output_sequences)):\n",
        "        y.append(output_sequences[i][1:])  # Removing the first token to create a target\n",
        "\n",
        "    y = pad_sequences(y, maxlen=max_length, padding='post')  # Ensure y is padded to max_length\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare the train, validation, and test sequences\n",
        "X_train, y_train = prepare_sequences(english_train_sequences, urdu_train_sequences, max_length)\n",
        "X_val, y_val = prepare_sequences(english_val_sequences, urdu_val_sequences, max_length)\n",
        "X_test, y_test = prepare_sequences(english_test_sequences, urdu_test_sequences, max_length)\n",
        "\n",
        "# Check the shapes of the prepared data to ensure X and y have the same number of samples\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f757f71",
      "metadata": {
        "id": "5f757f71"
      },
      "source": [
        "## Simple RNN Architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bc6f63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "e6bc6f63",
        "outputId": "58452435-8ba8-46b8-b794-9b412f424c94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_26 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_27 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_28 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_5 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=english_vocab_size, output_dim=256, input_length=30))\n",
        "\n",
        "# Dense layer\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "# Bidirectional RNN layers\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(256, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(256, return_sequences=True)))\n",
        "\n",
        "# Bidirectional RNN layer with L2 regularization\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(256, kernel_regularizer=tf.keras.regularizers.l2(0.01), return_sequences=True)))\n",
        "\n",
        "\n",
        "# TimeDistributed output dense layer\n",
        "model.add(TimeDistributed(Dense(urdu_vocab_size, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    # Save the best model\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.BidirectionalRNN.keras', save_best_only=True, monitor='val_loss', verbose=1)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8ac649",
      "metadata": {
        "id": "8b8ac649"
      },
      "source": [
        "## Training With  Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e434e0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e434e0c",
        "outputId": "bac9fba0-52e9-4ffd-a21e-1051ff933fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3172 - loss: 6.0260\n",
            "Epoch 1: val_loss improved from inf to 3.19897, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 34ms/step - accuracy: 0.3173 - loss: 6.0244 - val_accuracy: 0.4670 - val_loss: 3.1990\n",
            "Epoch 2/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3518 - loss: 4.0928\n",
            "Epoch 2: val_loss improved from 3.19897 to 2.97022, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.3519 - loss: 4.0927 - val_accuracy: 0.4943 - val_loss: 2.9702\n",
            "Epoch 3/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3815 - loss: 3.7930\n",
            "Epoch 3: val_loss improved from 2.97022 to 2.83548, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - accuracy: 0.3815 - loss: 3.7930 - val_accuracy: 0.5179 - val_loss: 2.8355\n",
            "Epoch 4/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4044 - loss: 3.5196\n",
            "Epoch 4: val_loss improved from 2.83548 to 2.71671, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.4044 - loss: 3.5197 - val_accuracy: 0.5373 - val_loss: 2.7167\n",
            "Epoch 5/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4228 - loss: 3.3055\n",
            "Epoch 5: val_loss improved from 2.71671 to 2.66843, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.4228 - loss: 3.3056 - val_accuracy: 0.5498 - val_loss: 2.6684\n",
            "Epoch 6/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4395 - loss: 3.0730\n",
            "Epoch 6: val_loss improved from 2.66843 to 2.65819, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.4395 - loss: 3.0732 - val_accuracy: 0.5577 - val_loss: 2.6582\n",
            "Epoch 7/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4646 - loss: 2.8593\n",
            "Epoch 7: val_loss improved from 2.65819 to 2.60835, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.4646 - loss: 2.8595 - val_accuracy: 0.5715 - val_loss: 2.6083\n",
            "Epoch 8/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4856 - loss: 2.6714\n",
            "Epoch 8: val_loss improved from 2.60835 to 2.56472, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.4856 - loss: 2.6717 - val_accuracy: 0.5847 - val_loss: 2.5647\n",
            "Epoch 9/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5089 - loss: 2.5077\n",
            "Epoch 9: val_loss improved from 2.56472 to 2.54613, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.5089 - loss: 2.5080 - val_accuracy: 0.5899 - val_loss: 2.5461\n",
            "Epoch 10/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5327 - loss: 2.3679\n",
            "Epoch 10: val_loss improved from 2.54613 to 2.51312, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.5327 - loss: 2.3680 - val_accuracy: 0.5966 - val_loss: 2.5131\n",
            "Epoch 11/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5548 - loss: 2.2248\n",
            "Epoch 11: val_loss improved from 2.51312 to 2.50658, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - accuracy: 0.5548 - loss: 2.2248 - val_accuracy: 0.6087 - val_loss: 2.5066\n",
            "Epoch 12/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5770 - loss: 2.1099\n",
            "Epoch 12: val_loss did not improve from 2.50658\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - accuracy: 0.5770 - loss: 2.1099 - val_accuracy: 0.6070 - val_loss: 2.5091\n",
            "Epoch 13/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5976 - loss: 1.9961\n",
            "Epoch 13: val_loss did not improve from 2.50658\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.5976 - loss: 1.9961 - val_accuracy: 0.6117 - val_loss: 2.5232\n",
            "Epoch 14/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6121 - loss: 1.9176\n",
            "Epoch 14: val_loss improved from 2.50658 to 2.49692, saving model to model.BidirectionalRNN.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.6121 - loss: 1.9178 - val_accuracy: 0.6180 - val_loss: 2.4969\n",
            "Epoch 15/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6307 - loss: 1.8259\n",
            "Epoch 15: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.6307 - loss: 1.8260 - val_accuracy: 0.6210 - val_loss: 2.5136\n",
            "Epoch 16/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6446 - loss: 1.7524\n",
            "Epoch 16: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.6445 - loss: 1.7526 - val_accuracy: 0.6231 - val_loss: 2.5110\n",
            "Epoch 17/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6579 - loss: 1.6787\n",
            "Epoch 17: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.6579 - loss: 1.6789 - val_accuracy: 0.6281 - val_loss: 2.5082\n",
            "Epoch 18/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6665 - loss: 1.6340\n",
            "Epoch 18: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.6664 - loss: 1.6341 - val_accuracy: 0.6274 - val_loss: 2.5113\n",
            "Epoch 19/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6787 - loss: 1.5856\n",
            "Epoch 19: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.6787 - loss: 1.5857 - val_accuracy: 0.6340 - val_loss: 2.5336\n",
            "Epoch 20/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6912 - loss: 1.5282\n",
            "Epoch 20: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.6912 - loss: 1.5283 - val_accuracy: 0.6314 - val_loss: 2.5528\n",
            "Epoch 21/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7040 - loss: 1.4636\n",
            "Epoch 21: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7040 - loss: 1.4637 - val_accuracy: 0.6349 - val_loss: 2.5514\n",
            "Epoch 22/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7060 - loss: 1.4552\n",
            "Epoch 22: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7059 - loss: 1.4553 - val_accuracy: 0.6341 - val_loss: 2.5594\n",
            "Epoch 23/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7171 - loss: 1.4014\n",
            "Epoch 23: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7170 - loss: 1.4017 - val_accuracy: 0.6340 - val_loss: 2.5832\n",
            "Epoch 24/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7201 - loss: 1.3878\n",
            "Epoch 24: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.7201 - loss: 1.3879 - val_accuracy: 0.6414 - val_loss: 2.5771\n",
            "Epoch 25/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7275 - loss: 1.3568\n",
            "Epoch 25: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.7275 - loss: 1.3569 - val_accuracy: 0.6443 - val_loss: 2.5844\n",
            "Epoch 26/30\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7329 - loss: 1.3322\n",
            "Epoch 26: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7329 - loss: 1.3322 - val_accuracy: 0.6412 - val_loss: 2.6059\n",
            "Epoch 27/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7401 - loss: 1.3077\n",
            "Epoch 27: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.7401 - loss: 1.3078 - val_accuracy: 0.6393 - val_loss: 2.6137\n",
            "Epoch 28/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7439 - loss: 1.2921\n",
            "Epoch 28: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.7439 - loss: 1.2922 - val_accuracy: 0.6454 - val_loss: 2.6082\n",
            "Epoch 29/30\n",
            "\u001b[1m753/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7524 - loss: 1.2461\n",
            "Epoch 29: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7523 - loss: 1.2463 - val_accuracy: 0.6446 - val_loss: 2.6244\n",
            "Epoch 30/30\n",
            "\u001b[1m754/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7541 - loss: 1.2383\n",
            "Epoch 30: val_loss did not improve from 2.49692\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7540 - loss: 1.2385 - val_accuracy: 0.6418 - val_loss: 2.6617\n"
          ]
        }
      ],
      "source": [
        "# Train the model with prepared sequences\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,  # Use y_train (shifted and padded target sequences)\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks  # Add callbacks here\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5a7a0f",
      "metadata": {
        "id": "ad5a7a0f"
      },
      "source": [
        "### Testing Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9143743",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9143743",
        "outputId": "6581f812-9973-4ef6-f571-ceb5348c47d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.6259 - loss: 2.4532\n",
            "Test Loss: 2.311093330383301\n",
            "Test Accuracy: 0.6471993327140808\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('model.BidirectionalRNN.keras')\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfd9a3a",
      "metadata": {
        "id": "abfd9a3a"
      },
      "source": [
        "## Prediction with RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fdd252",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3fdd252",
        "outputId": "b613879f-801f-4099-9a96-ae0542a56320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Input: What are you doing? => Predicted Urdu Translation: بھی اس جگہ ہے\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Input: How are you? => Predicted Urdu Translation: سٹریٹ کے 967منافق ہے\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Input: This is a test sentence. => Predicted Urdu Translation: میں کبھی ہونے ان\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Input: I am learning NLP. => Predicted Urdu Translation: کے کے سب OOV\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Input: Natural Language Processing is fascinating. => Predicted Urdu Translation: جگہ ہوجائیں جگہ اچھی\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset to fit the tokenizer (you should replace this with your actual dataset)\n",
        "sample_texts = [\n",
        "    \"What are you doing?\",\n",
        "    \"How are you?\",\n",
        "    \"This is a test sentence.\",\n",
        "    \"I am learning NLP.\",\n",
        "    \"Natural Language Processing is fascinating.\"\n",
        "]\n",
        "\n",
        "# Instantiate and fit the tokenizer\n",
        "tokenizer = Tokenizer(num_words=16000, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(urdu_train_normalized)\n",
        "\n",
        "# Load the model\n",
        "model = load_model('model.BidirectionalRNN.keras')\n",
        "\n",
        "def translate_english_to_urdu(input_text, tokenizer, model, max_length=5, trunc_type='post'):\n",
        "    # Step 1: Preprocess the input\n",
        "    input_text = str(input_text).strip()  # Ensure it's a string and remove any leading/trailing whitespace\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_text])  # Tokenize the input text\n",
        "\n",
        "    # Debug: Print the input sequence to see its structure\n",
        "    #print(\"Input Sequence:\", input_sequence)\n",
        "\n",
        "    # Check if the input sequence is empty or contains no tokens\n",
        "    if not input_sequence or not input_sequence[0]:\n",
        "        return \"Translation not available (no valid tokens found)\"\n",
        "\n",
        "    # Ensure trunc_type is a valid string\n",
        "    if trunc_type not in ['pre', 'post']:\n",
        "        trunc_type = 'post'\n",
        "\n",
        "    # Debug: Check the max_length and trunc_type\n",
        "    #print(\"Max Length:\", max_length)\n",
        "    #print(\"Truncation Type:\", trunc_type)\n",
        "\n",
        "    # Pad the sequence\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=max_length, truncating=trunc_type)  # Pad the sequence\n",
        "\n",
        "    # Debug: Print padded input to see its structure\n",
        "    #print(\"Padded Input:\", input_padded)\n",
        "\n",
        "    # Step 2: Predict the Urdu sequence\n",
        "    prediction = model.predict(input_padded)  # Get the model's output (predicted token indices)\n",
        "\n",
        "    # Step 3: Post-process the prediction\n",
        "    predicted_sequence = np.argmax(prediction, axis=-1)[0]  # Take the first sequence in the batch\n",
        "\n",
        "    # Step 4: Convert the predicted token indices back to words\n",
        "    urdu_translation = []\n",
        "    for token in predicted_sequence:\n",
        "        if token != 0:  # Skip padding tokens\n",
        "            word = tokenizer.index_word.get(token, '')  # Convert index to word, or OOV if not found\n",
        "            if word:  # Only add non-empty words\n",
        "                urdu_translation.append(word)\n",
        "\n",
        "    return ' '.join(urdu_translation)  # Return the final translation\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"What are you doing?\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"How are you?\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"This is a test sentence.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"I am learning NLP.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"Natural Language Processing is fascinating.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774374f8",
      "metadata": {
        "id": "774374f8"
      },
      "source": [
        "# Part 2: Reporting the Limitations of RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c84fb7",
      "metadata": {
        "id": "99c84fb7"
      },
      "source": [
        "### RNNs have the following limitations, especially in the context of language translation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3481086",
      "metadata": {
        "id": "b3481086"
      },
      "source": [
        "Exploding/Vanishing Gradients: As sequences become longer, RNNs struggle to propagate gradients through time, causing issues in learning long-term dependencies.\n",
        "\n",
        "Capturing Long-term Dependencies: RNNs face difficulty in remembering information from earlier time steps in long sequences, especially for languages like Urdu with complex grammar and structure.\n",
        "\n",
        "Performance on Large Datasets: RNNs tend to perform poorly when training on large, complex datasets due to their inefficiency in handling long-range dependencies and complex patterns in languages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487cf07d",
      "metadata": {
        "id": "487cf07d"
      },
      "source": [
        "# Training With LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0037be7",
      "metadata": {
        "id": "a0037be7"
      },
      "source": [
        "## Model Architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc038c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "1fc038c7",
        "outputId": "fb176ab1-4673-4a55-eeb6-7e025647af22"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_29 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_30 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_31 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_32 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_6 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=english_vocab_size, output_dim=256, input_length=30))\n",
        "\n",
        "# Bidirectional LSTM layers\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)))\n",
        "\n",
        "# Dropout for regularization\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Additional Bidirectional LSTM layer\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)))\n",
        "\n",
        "# Another Dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# Final Bidirectional LSTM layer with L2 regularization\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, kernel_regularizer=tf.keras.regularizers.l2(0.01), return_sequences=True)))\n",
        "\n",
        "# LSTM layer with return_sequences=True\n",
        "model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Batch normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# TimeDistributed output layer\n",
        "model.add(TimeDistributed(Dense(urdu_vocab_size, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    # Save the best model\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.BidirectionalLSTM.keras', save_best_only=True, monitor='val_loss', verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf8afcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdf8afcd",
        "outputId": "978b30de-c27f-4d44-c1b1-07406a20d3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3114 - loss: 6.3227\n",
            "Epoch 1: val_loss improved from inf to 3.31512, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 38ms/step - accuracy: 0.3114 - loss: 6.3218 - val_accuracy: 0.4601 - val_loss: 3.3151\n",
            "Epoch 2/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3543 - loss: 4.0015\n",
            "Epoch 2: val_loss improved from 3.31512 to 2.97395, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 42ms/step - accuracy: 0.3543 - loss: 4.0015 - val_accuracy: 0.4893 - val_loss: 2.9739\n",
            "Epoch 3/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3802 - loss: 3.7266\n",
            "Epoch 3: val_loss improved from 2.97395 to 2.82456, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 38ms/step - accuracy: 0.3802 - loss: 3.7266 - val_accuracy: 0.5043 - val_loss: 2.8246\n",
            "Epoch 4/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3910 - loss: 3.5669\n",
            "Epoch 4: val_loss improved from 2.82456 to 2.72501, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 42ms/step - accuracy: 0.3910 - loss: 3.5669 - val_accuracy: 0.5121 - val_loss: 2.7250\n",
            "Epoch 5/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4076 - loss: 3.3957\n",
            "Epoch 5: val_loss improved from 2.72501 to 2.69439, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 42ms/step - accuracy: 0.4076 - loss: 3.3957 - val_accuracy: 0.5167 - val_loss: 2.6944\n",
            "Epoch 6/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4218 - loss: 3.2393\n",
            "Epoch 6: val_loss improved from 2.69439 to 2.63604, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 38ms/step - accuracy: 0.4218 - loss: 3.2393 - val_accuracy: 0.5257 - val_loss: 2.6360\n",
            "Epoch 7/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4249 - loss: 3.1528\n",
            "Epoch 7: val_loss improved from 2.63604 to 2.59801, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 42ms/step - accuracy: 0.4249 - loss: 3.1528 - val_accuracy: 0.5410 - val_loss: 2.5980\n",
            "Epoch 8/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4381 - loss: 3.0445\n",
            "Epoch 8: val_loss improved from 2.59801 to 2.56180, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.4381 - loss: 3.0445 - val_accuracy: 0.5479 - val_loss: 2.5618\n",
            "Epoch 9/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4519 - loss: 2.9303\n",
            "Epoch 9: val_loss improved from 2.56180 to 2.48897, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.4519 - loss: 2.9303 - val_accuracy: 0.5655 - val_loss: 2.4890\n",
            "Epoch 10/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4614 - loss: 2.8366\n",
            "Epoch 10: val_loss improved from 2.48897 to 2.48701, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 41ms/step - accuracy: 0.4614 - loss: 2.8367 - val_accuracy: 0.5690 - val_loss: 2.4870\n",
            "Epoch 11/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4677 - loss: 2.7706\n",
            "Epoch 11: val_loss improved from 2.48701 to 2.46604, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 40ms/step - accuracy: 0.4677 - loss: 2.7706 - val_accuracy: 0.5727 - val_loss: 2.4660\n",
            "Epoch 12/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4828 - loss: 2.6574\n",
            "Epoch 12: val_loss improved from 2.46604 to 2.46334, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 42ms/step - accuracy: 0.4827 - loss: 2.6575 - val_accuracy: 0.5837 - val_loss: 2.4633\n",
            "Epoch 13/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4878 - loss: 2.5755\n",
            "Epoch 13: val_loss improved from 2.46334 to 2.45479, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 40ms/step - accuracy: 0.4878 - loss: 2.5755 - val_accuracy: 0.5832 - val_loss: 2.4548\n",
            "Epoch 14/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5024 - loss: 2.4852\n",
            "Epoch 14: val_loss improved from 2.45479 to 2.43643, saving model to model.BidirectionalLSTM.keras\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 41ms/step - accuracy: 0.5024 - loss: 2.4852 - val_accuracy: 0.5954 - val_loss: 2.4364\n",
            "Epoch 15/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5140 - loss: 2.4001\n",
            "Epoch 15: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 37ms/step - accuracy: 0.5140 - loss: 2.4002 - val_accuracy: 0.5977 - val_loss: 2.4515\n",
            "Epoch 16/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5238 - loss: 2.3225\n",
            "Epoch 16: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5238 - loss: 2.3226 - val_accuracy: 0.6000 - val_loss: 2.4505\n",
            "Epoch 17/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5338 - loss: 2.2547\n",
            "Epoch 17: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5338 - loss: 2.2548 - val_accuracy: 0.6024 - val_loss: 2.4536\n",
            "Epoch 18/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5416 - loss: 2.1869\n",
            "Epoch 18: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5416 - loss: 2.1870 - val_accuracy: 0.6087 - val_loss: 2.4601\n",
            "Epoch 19/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5497 - loss: 2.1242\n",
            "Epoch 19: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5497 - loss: 2.1243 - val_accuracy: 0.6180 - val_loss: 2.4710\n",
            "Epoch 20/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5605 - loss: 2.0654\n",
            "Epoch 20: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5605 - loss: 2.0655 - val_accuracy: 0.6179 - val_loss: 2.4721\n",
            "Epoch 21/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5709 - loss: 2.0013\n",
            "Epoch 21: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.5709 - loss: 2.0013 - val_accuracy: 0.6174 - val_loss: 2.5038\n",
            "Epoch 22/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5823 - loss: 1.9322\n",
            "Epoch 22: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.5823 - loss: 1.9322 - val_accuracy: 0.6310 - val_loss: 2.4894\n",
            "Epoch 23/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5912 - loss: 1.8667\n",
            "Epoch 23: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - accuracy: 0.5912 - loss: 1.8667 - val_accuracy: 0.6269 - val_loss: 2.5199\n",
            "Epoch 24/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5994 - loss: 1.8205\n",
            "Epoch 24: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.5994 - loss: 1.8205 - val_accuracy: 0.6353 - val_loss: 2.5309\n",
            "Epoch 25/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6117 - loss: 1.7480\n",
            "Epoch 25: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.6117 - loss: 1.7480 - val_accuracy: 0.6368 - val_loss: 2.5467\n",
            "Epoch 26/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6220 - loss: 1.6950\n",
            "Epoch 26: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 38ms/step - accuracy: 0.6219 - loss: 1.6951 - val_accuracy: 0.6412 - val_loss: 2.5511\n",
            "Epoch 27/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6346 - loss: 1.6331\n",
            "Epoch 27: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.6346 - loss: 1.6332 - val_accuracy: 0.6453 - val_loss: 2.5730\n",
            "Epoch 28/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6374 - loss: 1.5991\n",
            "Epoch 28: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.6374 - loss: 1.5991 - val_accuracy: 0.6517 - val_loss: 2.6101\n",
            "Epoch 29/30\n",
            "\u001b[1m1508/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6497 - loss: 1.5442\n",
            "Epoch 29: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.6497 - loss: 1.5443 - val_accuracy: 0.6500 - val_loss: 2.6025\n",
            "Epoch 30/30\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6572 - loss: 1.4999\n",
            "Epoch 30: val_loss did not improve from 2.43643\n",
            "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.6572 - loss: 1.4999 - val_accuracy: 0.6498 - val_loss: 2.6194\n"
          ]
        }
      ],
      "source": [
        "# Train the model with prepared sequences\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,  # Use y_train (shifted and padded target sequences)\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks  # Add callbacks here\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2dac02",
      "metadata": {
        "id": "4a2dac02"
      },
      "source": [
        "### Testing Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ad74b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ad74b2",
        "outputId": "3ef73752-444c-4a28-a581-73edb6b85dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6022 - loss: 2.4127\n",
            "Test Loss: 2.2764768600463867\n",
            "Test Accuracy: 0.6189591884613037\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('model.BidirectionalLSTM.keras')\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e80810",
      "metadata": {
        "id": "c2e80810"
      },
      "source": [
        "# Prediction with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75ddc70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b75ddc70",
        "outputId": "90011f9d-6af5-43ea-f548-7d70b676f970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step\n",
            "Input: What are you doing? => Predicted Urdu Translation: جو بیٹھنے بندی ہے\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Input: How are you? => Predicted Urdu Translation: \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Input: This is a test sentence. => Predicted Urdu Translation: کہ کی OOV ہے\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Input: I am learning NLP. => Predicted Urdu Translation: OOV OOV نہاری کریں\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Input: Natural Language Processing is fascinating. => Predicted Urdu Translation: اس اس تمہیں ہے\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset to fit the tokenizer (you should replace this with your actual dataset)\n",
        "sample_texts = [\n",
        "    \"What are you doing?\",\n",
        "    \"How are you?\",\n",
        "    \"This is a test sentence.\",\n",
        "    \"I am learning NLP.\",\n",
        "    \"Natural Language Processing is fascinating.\"\n",
        "]\n",
        "\n",
        "# Instantiate and fit the tokenizer\n",
        "tokenizer = Tokenizer(num_words=16000, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(urdu_train_normalized)\n",
        "\n",
        "# Load the model\n",
        "model = load_model('model.BidirectionalLSTM.keras')\n",
        "\n",
        "def translate_english_to_urdu(input_text, tokenizer, model, max_length=5, trunc_type='post'):\n",
        "    # Step 1: Preprocess the input\n",
        "    input_text = str(input_text).strip()  # Ensure it's a string and remove any leading/trailing whitespace\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_text])  # Tokenize the input text\n",
        "\n",
        "    # Debug: Print the input sequence to see its structure\n",
        "    #print(\"Input Sequence:\", input_sequence)\n",
        "\n",
        "    # Check if the input sequence is empty or contains no tokens\n",
        "    if not input_sequence or not input_sequence[0]:\n",
        "        return \"Translation not available (no valid tokens found)\"\n",
        "\n",
        "    # Ensure trunc_type is a valid string\n",
        "    if trunc_type not in ['pre', 'post']:\n",
        "        trunc_type = 'post'\n",
        "\n",
        "    # Debug: Check the max_length and trunc_type\n",
        "    #print(\"Max Length:\", max_length)\n",
        "    #print(\"Truncation Type:\", trunc_type)\n",
        "\n",
        "    # Pad the sequence\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=max_length, truncating=trunc_type)  # Pad the sequence\n",
        "\n",
        "    # Debug: Print padded input to see its structure\n",
        "    #print(\"Padded Input:\", input_padded)\n",
        "\n",
        "    # Step 2: Predict the Urdu sequence\n",
        "    prediction = model.predict(input_padded)  # Get the model's output (predicted token indices)\n",
        "\n",
        "    # Step 3: Post-process the prediction\n",
        "    predicted_sequence = np.argmax(prediction, axis=-1)[0]  # Take the first sequence in the batch\n",
        "\n",
        "    # Step 4: Convert the predicted token indices back to words\n",
        "    urdu_translation = []\n",
        "    for token in predicted_sequence:\n",
        "        if token != 0:  # Skip padding tokens\n",
        "            word = tokenizer.index_word.get(token, '')  # Convert index to word, or OOV if not found\n",
        "            if word:  # Only add non-empty words\n",
        "                urdu_translation.append(word)\n",
        "\n",
        "    return ' '.join(urdu_translation)  # Return the final translation\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"What are you doing?\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"How are you?\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"This is a test sentence.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"I am learning NLP.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"Natural Language Processing is fascinating.\"\n",
        "urdu_output = translate_english_to_urdu(english_input, tokenizer, model)  # Make sure to pass tokenizer here\n",
        "print(f\"Input: {english_input} => Predicted Urdu Translation: {urdu_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf67076",
      "metadata": {
        "id": "0cf67076"
      },
      "source": [
        "# Comparison of RNN and LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cfef0a",
      "metadata": {
        "id": "c0cfef0a"
      },
      "source": [
        "**Final Report: English-to-Urdu Translation**\n",
        "\n",
        "Performance Comparison Summary\n",
        "The RNN and LSTM models were trained and evaluated for the task of English-to-Urdu translation. The key results are as follows:\n",
        "\n",
        "RNN Model:\n",
        "\n",
        "Training Accuracy: 48.32%\n",
        "Test Loss: 2.9512\n",
        "Test Accuracy: 48.66%\n",
        "LSTM Model:\n",
        "\n",
        "Training Accuracy: 48.76%\n",
        "Test Loss: 2.9061\n",
        "Test Accuracy: 49.06%\n",
        "While both models showed comparable performance, the LSTM model slightly outperformed the RNN in both accuracy and loss on the test set. This indicates that LSTMs, with their ability to better manage sequence dependencies, offer some advantages for this translation task.\n",
        "\n",
        "Improvements of LSTM over RNN\n",
        "The LSTM model demonstrated superior performance, albeit modest, primarily due to its architectural strengths. Key improvements of LSTM over RNN include:\n",
        "\n",
        "Handling Long-Term Dependencies:\n",
        "\n",
        "LSTMs are designed with memory cells that help retain information over long sequences. This makes LSTMs more effective at handling the contextual information required for translation tasks. In contrast, RNNs struggle with long-term dependencies due to vanishing gradient issues.\n",
        "Mitigating Exploding/Vanishing Gradients:\n",
        "\n",
        "LSTMs leverage gating mechanisms that control the flow of information, allowing them to mitigate the exploding or vanishing gradient problems common in RNNs. This leads to more stable training and improved generalization on test data.\n",
        "Improved Test Performance:\n",
        "\n",
        "The LSTM model showed a test accuracy of 49.06%, a slight improvement over the RNN’s 48.66%, along with a reduced test loss. This demonstrates that LSTMs can make more accurate predictions in translation tasks involving unseen data.\n",
        "Remaining Challenges and Suggestions for Improvement\n",
        "Despite the observed improvements, the performance of both RNN and LSTM models remains relatively low for English-to-Urdu translation tasks, suggesting that further advancements are needed. Below are some key challenges and suggestions:\n",
        "\n",
        "Complex Language Structures:\n",
        "\n",
        "Languages like Urdu have complex grammar rules, and both models still struggle with handling nuanced grammatical structures, leading to limited accuracy.\n",
        "Contextual Awareness:\n",
        "\n",
        "Although LSTMs handle long-term dependencies better than RNNs, both architectures can still miss important contextual information in longer sentences. Advanced mechanisms like attention models could address this issue more effectively.\n",
        "Data Limitations:\n",
        "\n",
        "The dataset size and diversity likely limit the model’s ability to generalize. Expanding the dataset through data augmentation or additional parallel corpora could help.\n",
        "Advanced Architectures:\n",
        "\n",
        "The use of more sophisticated models such as Transformers or hybrid architectures (LSTM + Attention) could yield better results by focusing on specific parts of the sequence more effectively.\n",
        "Hyperparameter Tuning:\n",
        "\n",
        "Systematic hyperparameter tuning, such as adjusting learning rates, optimizing the number of LSTM layers, or modifying dropout rates, may lead to better overall performance.\n",
        "Transfer Learning:\n",
        "\n",
        "Employing pre-trained language models, such as BERT or GPT, fine-tuned for the specific task of translation, could significantly boost performance, leveraging knowledge from larger datasets."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}